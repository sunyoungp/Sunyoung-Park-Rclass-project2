---
title: "An example draft analysis script"
author: "Marguerite Butler"
date: "03/21/2023"
output: html_document
---

  
This Quarto file loads the cleaned Palmer Penguins data and does some initial analysis. I find this step very helpful for seeing what results you have to work with for your talk or paper/final report. 

Some of what is written below is for you. I would like you to modify this quarto file to produce a document customized for your analysis and written to explain your thinking in your data analysis so feel free to modify as much as you wish. 

It is worth taking a minute to reflect on where we are in the data analysis workflow. The purpose of the previous processing document was to document data cleaning and processing in preparation for analysis. You saw that as part of the cleaning and processing step, we already had to explore the data somewhat to understand how to clean it. In general, as you explore, you find more things that need cleaning. As you clean, you find more to explore. 

# The need to document your workflow

Although we broke our workflow in this project into cleaning and analysis steps, depending on your project, it may be more logical to divide the scripts in other ways. The organization should naturally reflect the workflow. 

In rather clean datasets at times it might make more sense to combine the cleaning and exploring code parts into a single R or Quarto file. _But if you do have real errors to fix, you will want to carefully document cleaning steps_, and probably not redo the cleaning each time you want to get a bit further on your data exploration and analysis. Itʻs a lot of baggage to carry around and also errors might creep in if you are keeping code in your script that you are not actively working on. 

When there are natural breaks in the workflow (i.e., when you close the door on cleaning or on a first analysis), it can be a good idea to have start a new script because once you clean your data, you will have a new starting point for all of your downstream analyses (and not look back at the really raw data, unless you want to change your mind about some of the cleaning - thus the need for keeping an original raw data file and documenting all the steps).  

This can also come up when you have a multi-stage analysis. In very complex analyses, it can make a lot of sense to have separate scripts for major analyses or workflow steps. As always, use your jugement, and be intentional about your organization. Clean organization = clear thinking.  


# Analysis 

If you did a good job in the previous step, you should have a pretty good idea of the structure of the data. 

For this part of the project, develop three questions and use your R skills to answer them. Begin by producing a summary table of the data that could be included in a future paper. You should produce plots or tables and/or statistics or model fits to address your questions. 

# Setup

This needs to run to load the R script so we can include the code chunks below.

```{r }
#| cache = FALSE
knitr::read_chunk('statistical_analysis.R')
```

Load needed packages and filepaths.  

```{r setup}
#| message: FALSE
#| warning: FALSE
```

Load custom functions.

```{r functions}
```

Load the data.

```{r loaddata}
```

# Create a summary table

In any paper you should always report a summary of the data. This includes basic statsistics for your data including sample size, counts, and means and standard errors for continuous data. 

Here we will use skimr which produces a summary table, but with more than we want. Letʻs save it as an object so we can grab the elements we want. 

It turns out that the `skim()` function returns a tibble. We can coerce it to a dataframe and use `head()` to see what the column names are and what the data look like. 

```{r, summarize}
```

## Select columns for a final summary table

Letʻs retain only the variable, N, mean, sd, and category counts, but letʻs rename them. Since we will use the SD to compute the stadard error letʻs just rename it as SE now and save a step later.  (Remember the standard error is just the standard deviation/ square root(sample size)). 

Note: The `results="asis"` is an option for `knitr` to layout the the results without the code formatting. Normally output from code chunks has the look of R output. `"asis"` (as in "as is", lol) removes that behavior, so we can lay it out as a typeset table for print. 

```{r summary.table, results="asis"}
```


# Do species differ in size?

As an example, letʻs ask the question _Do species differ in size?_ Our first try is a boxplot of mass by species:

```{r mass_species_boxplot}
```

The results were created by the `statistical_analysis.R` script and to the `Results` folder. Depending on how many tables/figures and workflow steps you have, it might make sense to have subfoldersf. Just choose a setup that makes sense for your project and works for you, and provide enough documentation that someone can understand what you are doing.

Now letʻs try a density plot

```{r mass_species_demsotu}
```

Provide a brief diescription of your results. To test the statistical significance of this result we can use ANOVA. We see that species do differ in size and this is a very robust statistical result. 

```{r mass_species_aov}
```

# Does the island have an affect on size?

What about an island effect? Since we know that species differ, we can include a two-way ANOVA and test both factors. 


When we add island to the model _after_ we account for species, it is not significant. 

```{r mass_species_island_aov}
```

However, if we add island _first, before_ species, it is signficant! We interpret this as islands differing in mass as well, but islands are not as different as species are in mass. 

```{r mass_island_species_aov}
```
Letʻs plot both factors together to see whatʻs going on. 

```{r mass_species_island_density}
```


# Notes

For your own explorations, tables and figures can be "quick and dirty". As long as you can see what's going on, there is no need to polish them. That's in contrast to figures you'll produce for your final products (paper, report, presentation, website, etc.). Those should look as nice, polished and easy to understand as possible.


