---
title: "An example cleaning script with code pulled in from R script"
author: "Marguerite Butler"
date: "2023-02-15"
output: html_document
---


# Processing script (data cleaning) with code pulled in from script

This is essentially the same as the other Quarto file, but now the code is not inside this file. Instead, it is pulled in from the R script using the code chunk labels.


# Setup

This needs to run to load the R script so we can include the code chunks below.

Note that you can pull in more than one R script if you want.

```{r, include=FALSE, cache=FALSE}
knitr::read_chunk('processingcode.R')
```

Load needed packages. Instead of having R commands here, we can have R do it by pulls in the code from the R script according to the labels. Here the code chuck below is replaced with the `packages` code chunk from `processingcode.R`. 


```{r, packages, message = FALSE, warning = FALSE}
```

# Data loading

Start R in the same directory that this script resides in `project_root/Code/Processing_code`.  If you need to check your working directory, use `getwd()`.

Either restart R in the correct directory, or navigate to it 
with `setwd(...relative path to the correct directory...)`. 

**NEVER** put a `setwd()` inside your code, it is bad ettiquite as it probably wonʻt work for anyone else. 

```{r, loaddata}
```

# Explore Data

### There are several ways of looking at the data

```{r, exploredata}
```


# Cleaning

Inspecting the data, we find some problems that need addressing. 

###  Species names

First, we know that this is a dataset for three species of penguin, but we notice that there are 9 unique species.

```{r, cleandata1}
```

Fix all of the errors. 

Also, letʻs shorten Species just keeping the three common names "Adelie", "Gentoo", and "Chinstrap" and delete the rest of the Species character string. 

NOTE: Check your work with each change.  Debug as you go, never all at once. Make sure that the code you save in your script works without error. 


### Continuous data

There is an entry for `Culmen Length (mm)` which says "missing" instead of a number or NA. 
Should we delete this record (and all of the variables)?
This "missing" entry also turned all culmen length entries into characters instead of numeric.
That conversion to character also means that our summary function isn't very meaningful.

So let's fix that first.

```{r, cleandata2}
```

Notice anything funny? 

Now we see that there are three penguins with really really long culmens (300+mm) that could be typos. If we don't know, we might need to remove these penguins. But let's suppose that we somehow know that this is because of a misplaced decimal point (for example if we could verify with field records), and letʻs fix this:

```{r, cleandata3.1}
```

Notice that NAʻs will match the condition `cl>300`, because we donʻt really know, so R returns it to be conservative. We donʻt want NAs, so letʻs exclude them with 
!is.na()  where the ! is "not" or the opposite of is.na. 
The logical & which requires both conditions to be true (i.e., I want to be rich AND famous):

```{r, cleandata3.2}
```


Look better?

### Now let's look at body mass.

There are penguins with body mass of <100g when the others are over 3000. 
Perhaps these are new chicks? But they are supposed to be adults. Letʻs remove them.

```{r, cleandata4.1}
```


Mass is the main size variable, so we will probably need to remove the individuals with missing masses in order to  be able to analyze the data. 

Note: Some analysis methods can deal with missing values, so it's not always necessary. Or it may be fine to have it in some of the variables but probably not the size variable. 
This should be adjusted based on your planned analysis approach. 

```{r, cleandata4.2}
```

Does it look better?

### Factors

We also want to have Species, Sex, and Island coded as a categorical/factor variable:

```{r, cleandata5}
```

# Bivariate Plots

Make bivariate plots for any remaining continous data to ensure there are no further errors. It is a good check on the distribution of the data as well. 

Make histograms or densities of at least mass by discrete category, to check for any potential category errors, extra categories, etc.  

You should look through all of the data, variable by variable, or by pairs of variables.


# Finalize your cleaned dataset. 

Drop any variables (columns) that you wonʻt analyze.  If you have extra levels after dropping some values, you may want to relevel your factors (this may or may not happen). 

To specify new levels or orders of levels:

```{r, finalizedata}
```
# Save data

All done, data is clean now. 
Let's assign at the end to some final variable
makes it easier to add steps above

```{r, savedata}
```

Finally, we save the clean data as RDS file. I suggest you save your processed and cleaned data as RDS or RDA/Rdata files, as well as a copy as .csv

RDS/Rdata preserves coding like factors, characters, numeric, etc.  If you save as CSV, that information would get lost.
However, CSV is better for sharing with others since it's plain text. If you do CSV, you might want to write down somewhere what each variable is (i.e. a data dictionary).


# Notes 

-  Anything you don't want loaded into the Quarto file but 
keep in the R file, just give it its own label and then just leave that label out of the Quarto file. For example, you may try excluding some of the excessive comments. 

-  Dealing with NA or "bad" data:
Removing anyone who had "faulty" or missing data is one approach, but it's often not the best. Based on your question and your analysis approach, you might want to do cleaning differently (e.g. keep individuals with some missing information)

-  Saving data as RDS:
I suggest you save your processed and cleaned data as RDS or RDA/Rdata files.  This preserves coding like factors, characters, numeric, etc.  If you save as CSV, that information would get lost.
However, CSV is better for sharing with others since it's plain text. 

-  If you do CSV, you must to write down somewhere what each variable is (i.e. in a data dictionary).

-  See here for some suggestions on how to store your processed data:
<http://www.sthda.com/english/wiki/saving-data-into-r-data-format-rds-and-rdata>
